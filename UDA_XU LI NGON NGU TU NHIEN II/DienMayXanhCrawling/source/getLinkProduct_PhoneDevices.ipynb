{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author: Ngo Van Uc\n",
    "Date: 31/05/2024\n",
    "Mail: ngovanuc.git@gmail.com\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***tasks:***\n",
    "\n",
    "- tìm điện thoại trên trang web điện máy xanh\n",
    "- khắc phục lỗi: 403 Forbiden\n",
    "- lấy ra các thuộc tính cần thiết và lưu vào file csv của các sản phẩm điện thoại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.request import Request\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "from bs4 import BeautifulSoup\n",
    "from csv import writer\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get all links v1\n",
    "v2 hoàn thiện hơn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***để tránh lỗi, mỗi khi quyét một trang web, chúng ta cần:***\n",
    "\n",
    "- mở thử môt trang web xem nó tồn tại không\n",
    "- nếu nó tồn tại thì xem server nó còn sống không =))\n",
    "- các truy vấn nên dùng ngoại lệ tránh ngắt quãng trong quá trình "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://www.thegioididong.com/dtdd\",\n",
    "    \"https://cellphones.com.vn/mobile.,\",\n",
    "    \"https://dienmaycholon.vn/dien-thoai-di-dong\",\n",
    "    \"https://www.nguyenkim.com/dien-thoai-di-dong/\",\n",
    "    \"https://viettelstore.vn/dien-thoai\",\n",
    "    \"https://didongviet.vn/dien-thoai.,\",\n",
    "    \"https://www.dienmayxanh.com/laptop\",\n",
    "    \"https://www.thegioididong.com/dtdd/iphone-15-pro?utm_flashsale=1\",\n",
    "    \"https://www.dienmayxanh.com/dien-thoai\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 403: Forbidden\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    link = urlopen(urls[8])\n",
    "    print('Its work!')\n",
    "except HTTPError as he:\n",
    "    print(he)\n",
    "except URLError as ue:\n",
    "    print(ue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***khắc phục lỗi 403: Forbiden***\n",
    "\n",
    "thông thường các trang web hiện đại đều sử dụng trình chặn các truy cập \n",
    "bất thường. vấn đề ở chỗ khi chúng ta gửi một trình yêu cầu thì máy chủ không\n",
    "thể biết được yêu cầu đến từ đâu.\n",
    "\n",
    "=> giải pháp đưa ra đó là cung cấp thông tin truy cập trình duyệt giả mạo\n",
    "\n",
    "\n",
    "trong trường hợp một người dùng giả lập có lượng truy cập lớn (thực hiện\n",
    "quá nhiều yêu cầu tới máy chủ), thông thường sẽ bị phát hiện và được xem\n",
    "là có lưu lượng truy cập bất thường, và được cho là BOT, lúc này sẽ bị chặn\n",
    "\n",
    "=> giải pháp đưa ra đó là: tạo một danh sách người dùng giả mạo và dùng random\n",
    "để truy cập, tránh việc một người dùng giả lập truy cập quá nhiều (phân bổ\n",
    "lượng truy cập ra cho các gỉa lập)\n",
    "\n",
    "***references:***\n",
    "\n",
    "- https://medium.com/@speedforcerun/python-crawler-http-error-403-forbidden-1623ae9ba0f\n",
    "- https://www.useragentstring.com/pages/useragentstring.php?source=post_page-----1623ae9ba0f--------------------------------\n",
    "- https://www.useragentstring.com/pages/Chrome/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's work!\n"
     ]
    }
   ],
   "source": [
    "# User agent strings\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.140 Safari/537.36',\n",
    "]\n",
    "\n",
    "try:\n",
    "    request = Request(url=urls[8], headers={'User-Agent': random.choice(user_agents)})\n",
    "    print(\"It's work!\")\n",
    "except AttributeError as e:\n",
    "    print(e)\n",
    "except HTTPError as he:\n",
    "    print(he)\n",
    "except URLError as ue:\n",
    "    print(ue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***phân tích:***\n",
    "\n",
    "- trong đường link index 8 chứa các thẻ li bao gồm thông tin điện thoại\n",
    "- lọc hết các thẻ li\n",
    "- trong thẻ li có các thông tin quan trọng của sản phẩm cần lấy ra\n",
    "- lưu vào trong một file csv chứa các thông tin quan trọng cần lấy ra\n",
    "\n",
    "***lưu ý:***\n",
    "\n",
    "- hiện tại chưa thể lấy hết các sản phẩm được do mỗi sản phẩm có nhiều phiên bản\n",
    "- select các phiên bản đó và lưu trang web về để thực hiện lấy đầy đủ data hơn\n",
    "- => chọn các phiên bản sản phẩm rồi nhấn lưu trang web đó vào ổ đĩa E:/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_file_v1 = \"E:/Điện thoại smartphone giá rẻ, chính hãng, cũ đổi mới, góp 0% - 04_2024.html\"\n",
    "html_file_v2 = \"E:/Điện thoại smartphone giá rẻ, chính hãng, cũ đổi mới, góp 0% - 04_2024 - v2.html\"\n",
    "html_file_v3 = \"E:/Điện thoại smartphone giá rẻ, chính hãng, cũ đổi mới, góp 0% - 04_2024 - v3.html\"\n",
    "html = open(html_file_v3, 'r', encoding='utf-8')\n",
    "html_contents = html.read()\n",
    "bs = BeautifulSoup(html_contents, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagList = bs.find_all('li', {'class': 'item ajaxed __cate_42'})\n",
    "print(len(tagList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = []\n",
    "BEST_COLUMNS = []\n",
    "REMOVED_COLUMNS = []\n",
    "PRE_LINK = \"https://www.dienmayxanh.com/\"\n",
    "\n",
    "for tag in tagList:\n",
    "    \n",
    "    for key, value in tag.attrs.items():\n",
    "        COLUMNS.append(key)\n",
    "\n",
    "    child = tag.find('a', {'class': 'main-contain'})    \n",
    "    for key, _ in child.attrs.items():\n",
    "        COLUMNS.append(key)\n",
    "\n",
    "    # sản phẩm chứa nhiều thông số khác nhau với số lượng thông số cũng không cố định\n",
    "    child = tag.find('div', {'class': 'item-compare'})\n",
    "    for key, _ in child.attrs.items():\n",
    "        COLUMNS.append(key)\n",
    "\n",
    "    child = tag.find('p', {'class': 'item-rating-total'})\n",
    "    COLUMNS.append(child.get('class')[0])\n",
    "    \n",
    "    break\n",
    "\n",
    "\n",
    "print(COLUMNS)\n",
    "print(len(COLUMNS)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from csv import writer\n",
    "\n",
    "BEST_COLUMNS = ['data-id', 'data-productcode', 'data-price', \n",
    "                'href', 'data-name', 'data-id', 'data-price', \n",
    "                'data-brand', 'data-cate', 'item-rating-total']\n",
    "\n",
    "csv_filePath = \"E:/UDA_LEARNING/UDA_XU LI NGON NGU TU NHIEN II/DienMayXanhCrawling/data/getLinkProduct_PhoneDevices.csv\"\n",
    "csv_file = open(csv_filePath, 'a', newline='', encoding='utf-8')\n",
    "writer = csv.writer(csv_file)\n",
    "writer.writerow(BEST_COLUMNS)\n",
    "\n",
    "count = 0\n",
    "for tag in tagList:\n",
    "    dataRow = []\n",
    "\n",
    "    for key, value in tag.attrs.items():\n",
    "        if key in BEST_COLUMNS:\n",
    "            dataRow.append(value)\n",
    "\n",
    "    for key, value in tag.find('a', {'class': 'main-contain'}).attrs.items():\n",
    "        if key in BEST_COLUMNS:\n",
    "            dataRow.append(value)  \n",
    "\n",
    "    rating = tag.find('p', {'class': 'item-rating-total'})\n",
    "    if rating is not None:\n",
    "        dataRow.append(rating.get_text())\n",
    "    else:\n",
    "        dataRow.append('0')\n",
    "    \n",
    "    writer.writerow(dataRow)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html.close()\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***note***\n",
    "\n",
    "các danh mục sản phẩm được lấy trong file csv có thể bị trùng nhau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get all links v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ý tưởng:***\n",
    "\n",
    "Object: điện thoại, máy tính, tivi, tủ lạnh...\n",
    "- b1: có được các link sản phẩm cần lấy\n",
    "- b2: từ các link của b1, lấy được link đầy đủ chứa truy vấn hiển thị tất cả các sản phẩm -> lưu vào csv (getLinkContainAllProductsOfObject.csv)\n",
    "- b3: từ các link của b2, lúc này sẽ có tất cả danh sách các sản phẩm và lúc đó ta lấy link của chúng -> lưu vào csv (getLinkAllProducts.csv) (iphone11, iphone12 sẽ là 2 sản phẩm khác nhau)\n",
    "- b4: từ các link của b3, ta sẽ phải lấy được link của mỗi phiên bản sản phẩm -> lưu vào csv (getLinkVisionOfAllProducts.csv)\n",
    "- b5: từ các link b4, ta đã có đầy đủ và gần như hoàn thiện các thông tin cần lấy đều có tại đó, lúc này ta cũng cần lấy được link đánh giá -> tất cả lưu vào csv (getLinkAndCategoricalOfVisionOfProducts.csv)\n",
    "- b6: từ link của b5, ta mở link và lấy tất cả comment và các thông số đánh giá của sản phẩm đó -> lưu vào csv (getAllCommentProducts.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b1\n",
    "linkObjects = [\n",
    "    \"https://www.dienmayxanh.com/tivi\",\n",
    "    \"https://www.dienmayxanh.com/tu-lanh\",\n",
    "    \"https://www.dienmayxanh.com/may-giat\",\n",
    "    \"https://www.dienmayxanh.com/may-lanh\",\n",
    "    \"https://www.dienmayxanh.com/may-loc-nuoc\",\n",
    "    \"https://www.dienmayxanh.com/tu-dong\",\n",
    "    \"https://www.dienmayxanh.com/dan-loa-dvd\",\n",
    "    \"https://www.dienmayxanh.com/quat-dieu-hoa\",\n",
    "    \"https://www.dienmayxanh.com/noi-chien-khong-dau\",\n",
    "    \"https://www.dienmayxanh.com/bep-tu\",\n",
    "    \"https://www.dienmayxanh.com/quat\",\n",
    "    \"https://www.dienmayxanh.com/may-say-quan-ao\",\n",
    "    \"https://www.dienmayxanh.com/dien-thoai\",\n",
    "]\n",
    "\n",
    "# ví dụ về sản phẩm điện thoại được truy vấn để hiển thị đầy đủ các loại\n",
    "# nhấn vào link mở trình duyệt để xem sự khác nhau nhé!\n",
    "link_allObjects_ex = [\n",
    "    \"https://www.dienmayxanh.com/dien-thoai?key=dien+thoai&sc=new#c=42&o=17&pi=5\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***phân tích:***\n",
    "\n",
    "- mỗi sản phẩm cần lấy sẽ có nhiều loại khác nhau (ví dụ sẽ có nhiều loại điện thoại khác nhau)\n",
    "- cần lấy được đường link nơi chứa truy vấn để hiển thị tất cả các sản phẩm\n",
    "- dưới đây sẽ thử nghiệm một sản phẩm là điện thoại và sẽ cố gắng lấy được đường link mà khi mở lên sẽ chứa tất cả các loại điện thoại bằng cách sau một vài lần nhấn xem thêm để hiển thị tất cả sản phẩm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = Chrome()\n",
    "driver.get(linkObjects[0])\n",
    "\n",
    "try:\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    html = driver.page_source\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    tag = bs.find_all('span', {'class': 'remain'})\n",
    "    remain = int(tag[0].get_text())\n",
    "    # print(remain)\n",
    "    # mỗi lần nhấn xem thêm để load thêm sản phẩm thì nó sẽ hiển thị thêm 20 sản phẩm\n",
    "    # như vậy số lần cần nhấn là (remain // 20), và cộng thêm 1 lần nữa nếu phần dư khác 0\n",
    "    number_of_clicks = remain // 20\n",
    "    if (remain % 20) != 0:\n",
    "        number_of_clicks += 1\n",
    "    # print(number_of_clicks)\n",
    "    # thay vì lằng nhằng tính toán số lần click thì hãy sử dụng vòng lặp while\n",
    "    \n",
    "    for i in range(0, number_of_clicks):\n",
    "        try:\n",
    "            view_more_div = wait.until(ec.presence_of_element_located((By.CLASS_NAME, \"view-more\")))\n",
    "            view_more_link = view_more_div.find_element(By.TAG_NAME, \"a\")\n",
    "            view_more_link.click()\n",
    "            # chờ một tí cho nó load xong đã -.-'\n",
    "            WebDriverWait(driver, 10).until(ec.url_changes(driver.current_url))\n",
    "            new_url = driver.current_url\n",
    "            print(f\"URL mới sau khi nhấn: {new_url}\")\n",
    "            # vì tốc độ nhấn của chương trình quá nhanh nên sẽ cho nó ngủ một thời gian ngắn để tránh làm tổn\n",
    "            # hại đến server của doanh nghiệp và tránh các trình chặn BOT tự động của họ\n",
    "            time.sleep(random.randint(10, 15))\n",
    "\n",
    "        except Exception:\n",
    "            print(f'Some error at {Exception}')\n",
    "            continue\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'Exception: {e}')\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some error at https://www.dienmayxanh.com/bep-tu\n"
     ]
    }
   ],
   "source": [
    "# b2\n",
    "getLinkContainAllProductsOfObject_path = \"E:/UDA_LEARNING/UDA_XU LI NGON NGU TU NHIEN II/DienMayXanhCrawling/data/getLinkContainAllProductsOfObject.csv\"\n",
    "getLinkContainAllProductsOfObject_csv = open(getLinkContainAllProductsOfObject_path, 'w', newline='', encoding='utf-8') # 'a' means appending mode, 'w' means writing mode\n",
    "writer = csv.writer(getLinkContainAllProductsOfObject_csv)\n",
    "writer.writerow(['link'])\n",
    "\n",
    "driver = Chrome()\n",
    "for link in linkObjects:\n",
    "    try:\n",
    "        driver.get(link)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "\n",
    "        html = driver.page_source\n",
    "        bs = BeautifulSoup(html, 'html.parser')\n",
    "        span_tag = bs.find_all('span', {'class': 'remain'})\n",
    "\n",
    "        remain = int(span_tag[0].get_text())\n",
    "        number_of_clicks = remain // 20\n",
    "        if (remain % 20) != 0:\n",
    "            number_of_clicks += 1\n",
    "\n",
    "        for i in range(0, number_of_clicks):\n",
    "            view_more_div = wait.until(ec.presence_of_element_located((By.CLASS_NAME, \"view-more\")))\n",
    "            view_more_link = view_more_div.find_element(By.TAG_NAME, \"a\")\n",
    "            view_more_link.click()\n",
    "            WebDriverWait(driver, 10).until(ec.url_changes(driver.current_url))\n",
    "\n",
    "            new_url = driver.current_url\n",
    "            time.sleep(random.randint(10, 15))\n",
    "\n",
    "        # sau khi vòng lặp chay xong ta luôn được link cuối cùng là link cần lấy, lúc này lưu nó vào file csv\n",
    "        writer.writerow([new_url])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Some error at {link}')\n",
    "        writer.writerow([new_url])\n",
    "        continue\n",
    "\n",
    "getLinkContainAllProductsOfObject_csv.close()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b3\n",
    "linkContainAllProductsOfObject = pd.read_csv(getLinkContainAllProductsOfObject_path)\n",
    "# getLinkAllProducts - file này chứa link khi mở lên + /danh-gia sẽ cho ra mục từng đánh giá sản phẩm\n",
    "getLinkAllProducts_path = \"E:/UDA_LEARNING/UDA_XU LI NGON NGU TU NHIEN II/DienMayXanhCrawling/data/getLinkAllProducts.csv\"\n",
    "getLinkAllProducts_csv = open(getLinkAllProducts_path, 'w', newline='', encoding='utf-8')\n",
    "writer = csv.writer(getLinkAllProducts_csv)\n",
    "writer.writerow(['data-brand', 'data-cate', 'href'])\n",
    "# class = main-contain, tag = a\n",
    "pre_href = \"https://www.dienmayxanh.com\"\n",
    "\n",
    "driver = Chrome()\n",
    "\n",
    "\n",
    "for idx in range(0, len(linkContainAllProductsOfObject)): \n",
    "    try:       \n",
    "        # link = linkContainAllProductsOfObject.iloc[idx, 0]\n",
    "        # link = \"https://www.dienmayxanh.com/bep-tu\"\n",
    "        driver.get(str(linkContainAllProductsOfObject.iloc[idx, 0]))\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "\n",
    "        html = driver.page_source\n",
    "        bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        a_tags = bs.find_all('a', {'class': 'main-contain'})    \n",
    "        # for key, value in a_tags[0].attrs.items():\n",
    "        #     print(key, value)\n",
    "        for tag in a_tags:\n",
    "            dataBrand = tag.get('data-brand')\n",
    "            dataCate = tag.get('data-cate')\n",
    "            href = pre_href + str(tag.get('href'))\n",
    "            writer.writerow([dataBrand, dataCate, href])\n",
    "        time.sleep(random.randint(10, 15))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Some error at {e}')\n",
    "        continue\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "getLinkAllProducts_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b4\n",
    "# có hai trường hợp xảy ra trong bước này:\n",
    "# - sản phẩm có nhiều phiên bản: iphone 11 64gb, iphone 11 128gb...\n",
    "# - hoặc là sản phẩm chỉ có 1 phiên bản duy nhất mà thôi\n",
    "# đoạn mã này đã được thêm try - except sau khi gặp lỗi để không bị ngắt quãng!\n",
    "\n",
    "getLinkAllProducts = pd.read_csv(getLinkAllProducts_path)\n",
    "getLinkVisionOfAllProducts_path = \"E:/UDA_LEARNING/UDA_XU LI NGON NGU TU NHIEN II/DienMayXanhCrawling/data/getLinkVisionOfAllProducts.csv\"\n",
    "getLinkVisionOfAllProducts_csv = open(getLinkVisionOfAllProducts_path, 'w', newline='', encoding='utf-8')\n",
    "writer = csv.writer(getLinkVisionOfAllProducts_csv)\n",
    "writer.writerow(['href'])\n",
    "pre_href = \"https://www.dienmayxanh.com\"\n",
    "\n",
    "driver = Chrome()\n",
    "\n",
    "for idx in range(0, len(getLinkAllProducts)):\n",
    "    try:\n",
    "        # ex_link = \"https://www.dienmayxanh.com/may-giat/may-giat-toshiba-8kg-aw-m905bvmk\"\n",
    "        # driver.get(ex_link)\n",
    "        driver.get(str(getLinkAllProducts.iloc[idx, 2]))\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        html = driver.page_source\n",
    "        bs = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        box_right = bs.find_all('div', {'class': 'box_right'})\n",
    "        scrolling_inner = box_right[0].find_all('div', {'class': 'scrolling_inner'})\n",
    "        if scrolling_inner:\n",
    "            # tức là sản phẩm có nhiều phiên bản\n",
    "            a_tags = scrolling_inner[0].find_all('a')\n",
    "            for a in a_tags:\n",
    "                href = pre_href + str(a.get('href'))\n",
    "                writer.writerow([href])             \n",
    "        else:\n",
    "            # đến đây thì sản phẩm chỉ có một phiên bản duy nhất\n",
    "            # comment_href = bs.find_all()\n",
    "            href = str(getLinkAllProducts.iloc[idx, 2])\n",
    "            writer.writerow([href])\n",
    "\n",
    "        # điều chỉnh thời gian ngủ hợp lí vì nếu không thời gian chạy chương trình sẽ rất lâu!\n",
    "        time.sleep(random.randint(10, 15))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Some error at {e}')\n",
    "        continue\n",
    "\n",
    "    \n",
    "# driver.quit()\n",
    "# getLinkVisionOfAllProducts_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()\n",
    "getLinkVisionOfAllProducts_csv.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***miêu tả công việc đến đây***\n",
    "\n",
    "hiện tại đến đây là đã có đường link dẫn đến sản phẩm đó rồi, công việc cần là lấy được đường link dẫn đến comment của sản phẩm đó, tuy nhiên có một vài vấn đề cần xem xét xử lí.\n",
    "\n",
    "- một sản phẩm có thể sẽ không có đánh giá nào -> ok bỏ qua sản phẩm đó\n",
    "- một sản phẩm sẽ có một trang đánh giá duy nhất (số lượng đánh giá ít) -> lấy comment trên trang đó là xong!\n",
    "- sản phẩm có nhiều hơn một trang đánh giá (số lượng comment đánh giá nhiều) -> luôn có một thẻ a chứa link dẫn đến trang đánh giá tiếp theo\n",
    "\n",
    "-> đến đây vấn đề đã được giải quyết thành 3 trường hợp cụ thể"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b5\n",
    "# đến đây nhiệm vụ chính là lấy được link dẫn đến trang có chứa tất cả comment\n",
    "# có một vấn đề phát sinh, sản phẩm có quá nhiều đánh giá thì các đánh giá sẽ bị ẩn...\n",
    "# một lần nữa phải lấy được link\n",
    "# ngoài ra cần lấy một vài thông số cần thiết của sản phẩm, để có thể sử dụng lại sau này\n",
    "# các thông tin này được lưu vào file: getLinkAndCategoricalOfVisionOfProducts.csv\n",
    "getLinkVisionOfAllProducts = pd.read_csv(getLinkVisionOfAllProducts_path)\n",
    "getLinkAndCategoricalOfVisionOfProducts_path = \"E:/UDA_LEARNING/UDA_XU LI NGON NGU TU NHIEN II/DienMayXanhCrawling/data/getLinkAndCategoricalOfVisionOfProducts.csv\"\n",
    "getLinkAndCategoricalOfVisionOfProducts_csv = open(getLinkAndCategoricalOfVisionOfProducts_path, 'w', newline='', encoding='utf-8')\n",
    "writer = csv.writer(getLinkAndCategoricalOfVisionOfProducts_csv)\n",
    "# ở đây chúng ta chỉ quan tâm tới comment nên các thông số khác sẽ bị bỏ qua\n",
    "writer.writerow(['href'])\n",
    "pre_href = \"https://www.dienmayxanh.com\"\n",
    "\n",
    "driver = Chrome()\n",
    "\n",
    "for idx in range(0, len(getLinkVisionOfAllProducts)):\n",
    "    try:\n",
    "        driver.get(str(getLinkVisionOfAllProducts.iloc[idx, 0]))\n",
    "        waiter = WebDriverWait(driver, 10)\n",
    "        html = driver.page_source\n",
    "        bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # tìm đường link đánh giá\n",
    "        hrefToViewAll = bs.find_all('a', {'class': 'c-btn-rate btn-view-all'})[0].get('href')\n",
    "        # nếu không có link đánh giá => bỏ qua\n",
    "        \n",
    "        # nếu có đường link đánh giá => cần phải mở nó và kiểm tra như dưới đây\n",
    "        if hrefToViewAll:            \n",
    "            try:\n",
    "                # mở đường link hrefToViewAll đó lên\n",
    "                driver.get(str(pre_href + hrefToViewAll))\n",
    "                # kiểm tra xem có nhiều comment được ẩn không? (quá nhiều comment sẽ được hiển thị qua các trang khác nhau)\n",
    "                moreCommentPage = bs.find_all('div', {'class': 'pagcomment'})\n",
    "                if moreCommentPage:\n",
    "                    # nếu các comment có trong nhiều trang và cần thực hiện truy vấn để lấy được tất cả các đường link đó\n",
    "                    # (tìm tất cả các thẻ a: driver.find_elements tìm tất cả các thẻ a trong div với class pagcomment)\n",
    "                    wait.until(ec.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.pagcomment a')))\n",
    "                    a_tags = driver.find_elements(By.CSS_SELECTOR, 'div.pagcomment a')\n",
    "                    href = driver.current_url\n",
    "                    writer.writerow([href])\n",
    "                    if a_tags:\n",
    "                        state = True\n",
    "                        before = driver.current_url\n",
    "                        while state:\n",
    "                            # nhấn bao lâu thì dừng lại đây? chúng ta không thể nào biết được khi nào thì sẽ dừng nhấn\n",
    "                            # vì cứ nhấn vào thẻ a cuối cùng thì nó vẫn sẽ chạy được bình thường\n",
    "                            # => so sánh đường link không thay đổi thì dừng việc nhấn                \n",
    "                            # Click vào thẻ a cuối cùng            \n",
    "                            a_tags[-1].click()\n",
    "                            WebDriverWait(driver, 10).until(ec.url_changes(driver.current_url))\n",
    "                            waiter = WebDriverWait(driver, 10)\n",
    "                            curent_href = driver.current_url\n",
    "                            if curent_href == before:\n",
    "                                state = False\n",
    "                            else:             \n",
    "                                before = driver.current_url                   \n",
    "                                writer.writerow([curent_href]) \n",
    "                                # tại đây cũng có thể lấy comment ngay và luôn!\n",
    "                                # CÓ THỂ LẤY COMMENT Ở ĐÂY BẰNG BEAUTIFULSOUP\n",
    "\n",
    "                else:\n",
    "                    # (không tìm thấy moreCommentPage tức là chỉ có 1 page comment thôi!)\n",
    "                    # nếu các comment chỉ gói gọn trong một trang duy nhất => lấy ngay đường link đó luôn\n",
    "                    href = driver.current_url\n",
    "                    writer.writerow([href])\n",
    "                    #  thực tế có thể lấy comment ngay tại đây luôn!\n",
    "                    # CÓ THỂ LẤY COMMENT Ở ĐÂY BẰNG BEAUTIFULSOUP\n",
    "\n",
    "            except Exception as ee:\n",
    "                print(f'Some error at {ee}')\n",
    "                continue\n",
    "    except Exception as e:\n",
    "        print(f'Some error at {e}')\n",
    "        continue\n",
    "\n",
    "driver.quit()\n",
    "getLinkAndCategoricalOfVisionOfProducts_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''mệt rồi không làm nữa!'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b6\n",
    "def vote(stars):\n",
    "    if stars <= 2 and stars >= 0:\n",
    "        return -1 # negative vote\n",
    "    elif stars == 3:\n",
    "        return 0 # neutral vote\n",
    "    elif stars >= 4 and stars <= 5:\n",
    "        return 1 # positive vote\n",
    "    else:\n",
    "        return 1000\n",
    "    \n",
    "getLinkAndCategoricalOfVisionOfProducts = pd.read_csv(getLinkAndCategoricalOfVisionOfProducts_path)\n",
    "getAllCommentProducts_path = \"E:/UDA_LEARNING/UDA_XU LI NGON NGU TU NHIEN II/DienMayXanhCrawling/data/getAllCommentProducts.csv\"\n",
    "getAllCommentProducts_csv = open(getAllCommentProducts_path, 'w', newline='', encoding='utf-8')\n",
    "writer = csv.writer(getAllCommentProducts_csv)\n",
    "writer.writerow(['comment', 'star', 'target'])\n",
    "\n",
    "driver = Chrome()\n",
    "for idx in range(0, len(getLinkAndCategoricalOfVisionOfProducts)):\n",
    "    try:\n",
    "        driver.get(str(getLinkAndCategoricalOfVisionOfProducts.iloc[idx, 0]))\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        html = driver.page_source\n",
    "        bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        li_tags = bs.find_all('li', {'class': 'par'})\n",
    "        # kiểm tra trang không tồn tại đánh giá sẽ bị bỏ qua (li_tags rỗng - None)\n",
    "        if li_tags:\n",
    "            for li in li_tags:\n",
    "                try:\n",
    "                    stars = len(li.find_all('i', {'class': 'iconcmt-starbuy'}))\n",
    "                    target = vote(stars=stars)\n",
    "                    comment = li.find('p', {'class': 'cmt-txt'})\n",
    "                    writer.writerow([comment, stars, target])\n",
    "                except Exception as e:\n",
    "                    print(f'Some error at {e}')\n",
    "                    continue\n",
    "            \n",
    "        time.sleep(random.randint(10, 15))\n",
    "    except Exception as e:\n",
    "        print(f'Some error at {e}')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''nhìn chung bài này có nhiều cách giải quyết khác nhau'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n",
      "3.0\n",
      "2.0\n",
      "error at 6/0\n",
      "1.5\n"
     ]
    }
   ],
   "source": [
    "ii = [1, 2, 3, 0, 4]\n",
    "a = 6\n",
    "\n",
    "for i in ii:\n",
    "    try:\n",
    "        print(a/i)\n",
    "    except Exception:\n",
    "        print(f'error at {a}/{i}')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n",
      "3.0\n",
      "2.0\n",
      "error at 6/0\n"
     ]
    }
   ],
   "source": [
    "ii = [1, 2, 3, 0, 4]\n",
    "a = 6\n",
    "\n",
    "try:\n",
    "    for i in ii:\n",
    "        print(a/i)\n",
    "except Exception:\n",
    "    print(f'error at {a}/{i}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
